{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3bd27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from Dataset import Image_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from Critic import Discriminator\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60468611",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Image_dataset(\"Dataset\")\n",
    "\n",
    "labels = []\n",
    "for i in range(len(ds)):\n",
    "    _, label = ds[i]\n",
    "    labels.append(ds[i][1])\n",
    "\n",
    "class_counts = Counter(labels)\n",
    "total_samples = len(labels)\n",
    "\n",
    "weight_per_class = {cls: total_samples/count for cls, count in class_counts.items()}\n",
    "weights = [weight_per_class[label] for label in labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "dl = DataLoader(ds, batch_size = 5, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde0eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Discriminator(in_channels=3)\n",
    "optimizer = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "BCE = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55470363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch Loss: 0.3802\n",
      "Epoch: 1 | Batch Loss: 0.3854\n",
      "Epoch: 2 | Batch Loss: 0.1661\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    batch_loss = 0\n",
    "    for data in dl:\n",
    "\n",
    "        x = data[0].to(DEVICE)\n",
    "        x = x.float()\n",
    "        critic_output = critic(x.permute(0, -1, 1, 2))\n",
    "        logits = critic_output.view(critic_output.shape[0], -1).mean(1)\n",
    "\n",
    "        labels = data[1]\n",
    "        targets = torch.tensor(\n",
    "            [1.0 if label == \"Not Defective\" else 0.0 for label in labels],\n",
    "            dtype=torch.float32,\n",
    "            device=critic_output.device\n",
    "        )\n",
    "        \n",
    "        loss = BCE(logits, targets)\n",
    "        batch_loss += loss.item()\n",
    "        critic.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Batch Loss: {batch_loss/len(dl):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdc975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defective\n"
     ]
    }
   ],
   "source": [
    "image_path = \"/Users/mohamedmafaz/Desktop/CountAI/Dataset/50.jpg\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),          \n",
    "])\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")  \n",
    "tensor_image = transform(image).unsqueeze(0)   \n",
    "\n",
    "if critic(tensor_image).view(tensor_image.shape[0], -1).mean(1) > 0.5:\n",
    "    print(\"Not Defective\")\n",
    "else:\n",
    "    print(\"Defective\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
