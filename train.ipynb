{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3bd27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from Dataset import Image_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from Critic import Discriminator\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60468611",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Image_dataset(\"Dataset\")\n",
    "\n",
    "labels = []\n",
    "for i in range(len(ds)):\n",
    "    _, label = ds[i]\n",
    "    labels.append(ds[i][1])\n",
    "\n",
    "class_counts = Counter(labels)\n",
    "total_samples = len(labels)\n",
    "\n",
    "weight_per_class = {cls: total_samples/count for cls, count in class_counts.items()}\n",
    "weights = [weight_per_class[label] for label in labels]\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "dl = DataLoader(ds, batch_size = 5, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde0eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Discriminator(in_channels=3)\n",
    "optimizer = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "BCE = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55470363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Batch Loss: 0.5361\n",
      "Epoch: 1 | Batch Loss: 0.4786\n",
      "Epoch: 2 | Batch Loss: 0.4949\n",
      "Epoch: 3 | Batch Loss: 0.3676\n",
      "Epoch: 4 | Batch Loss: 0.4039\n",
      "Epoch: 5 | Batch Loss: 0.5561\n",
      "Epoch: 6 | Batch Loss: 0.4663\n",
      "Epoch: 7 | Batch Loss: 0.3249\n",
      "Epoch: 8 | Batch Loss: 0.2548\n",
      "Epoch: 9 | Batch Loss: 0.5269\n"
     ]
    }
   ],
   "source": [
    "# Set the critic model to training mode\n",
    "critic.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    batch_loss = 0\n",
    "    for data in dl:\n",
    "        # Move input images to DEVICE and convert to float\n",
    "        x = data[0].to(DEVICE)\n",
    "        x = x.float()\n",
    "        # Forward pass through the critic, permute to (batch, channels, height, width)\n",
    "        critic_output = critic(x.permute(0, -1, 1, 2))\n",
    "        # Remove the channel dimension if it's 1\n",
    "        logits = critic_output.squeeze(1)\n",
    "        \n",
    "        # Get the labels from the batch\n",
    "        labels = data[1]\n",
    "        # Convert string labels to float targets: 1.0 for \"Not Defective\", 0.0 for \"Defective\"\n",
    "        targets = torch.tensor(\n",
    "            [1.0 if label == \"Not Defective\" else 0.0 for label in labels],\n",
    "            dtype=torch.float32,\n",
    "            device=critic_output.device\n",
    "        )\n",
    "        # Expand targets to match the shape of logits for pixel-wise loss\n",
    "        targets = torch.stack([torch.ones(logits.shape[1:]) if i == 1. else torch.zeros(logits.shape[1:]) for i in targets], 0).to(critic_output.device)\n",
    "        \n",
    "        # Compute the binary cross-entropy loss with logits\n",
    "        loss = BCE(logits, targets)\n",
    "        batch_loss += loss.item()\n",
    "        # Zero gradients, backpropagate, and update weights\n",
    "        critic.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print average batch loss for the epoch\n",
    "    print(f\"Epoch: {epoch} | Batch Loss: {batch_loss/len(dl):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d932a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(critic.state_dict(), \"critic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Discriminator(in_channels=3)\n",
    "critic.load_state_dict(torch.load(\"critic.pth\", map_location=torch.device('cpu'), weights_only=True))\n",
    "critic.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73cdc975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defective\n"
     ]
    }
   ],
   "source": [
    "image_path = \"/Users/mohamedmafaz/Desktop/CountAI/Dataset/59.jpg\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.ToTensor(),          \n",
    "])\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")  \n",
    "tensor_image = transform(image).unsqueeze(0)  \n",
    "\n",
    "result = critic(tensor_image)\n",
    "mat_min = result.min()\n",
    "mat_max = result.max()\n",
    "mat_normalized = (result - mat_min) / (mat_max - mat_min)\n",
    "mat_normalized = mat_normalized.view(tensor_image.shape[0], -1).mean(1)\n",
    "\n",
    "if mat_normalized > 0.5:\n",
    "    print(\"Not Defective\")\n",
    "else:\n",
    "    print(\"Defective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d33bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4401], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
